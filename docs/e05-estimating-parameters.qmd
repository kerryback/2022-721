---
title:  "Estimating Parameters"
author: <br><br><br><br><span style="font-family:perpetua; font-variant:small-caps; color:#606060;">Kerry Back</span><br><br><img src="RiceBusiness-transparent-logo-sm.png"  height=80>
output-dir: docs
execute:
  echo: false
  jupyter: python3
format: 
  revealjs:
    highlight-style: monokai
    code-fold: true
    slide-number: true
    preview-links: true
    self-contained: true
    transition: fade
    theme: [solarized, 721.scss]
    incremental: true
---

## Overview

- Using past samples to estimate means, standard deviations, and correlations is hazardous.
- Especially if there are many assets.
- Need long (stationary) time series of returns
- And/or some models.  Models limit the degrees of freedom and can help avoid overfitting.
- And/or some "penalization" -- constraints, etc.
- This session: past samples.



## Sampling Distributions

- Suppose returns $r_{1},\cdots,r_{n}$ are independent draws from a normal $(\mu,\sigma^2)$ distribution. 

- Let $m =$ sample mean and 
$s =$ sample std dev = $\sqrt{\sum_{i=1}^n \frac{(r_{i}-m)^2}{n-1}}$ 

- Then, $m$ is normal $(\mu,\sigma^2/n)$ and 
- $(n-1)s^2/\sigma^2$ is $\chi^2(n-1)$.


## Confidence Intervals

- Example: $n=25$, $m=0.12$, $s=0.30$.
- The estimated std dev (std error) of $\bar{r}$ is $0.30/\sqrt{25}=0.06$.
- A $95\%$ confidence interval for $\mu$ is 

. . .

$$0.12 Â± 1.96 \times 0.06 = [0.013,0.227]$$
- A similarly wide confidence interval for $\sigma$ is implied by the $\chi^2$ distribution. 

#

- We can sample more frequently to get better estimates of standard deviations and correlations.
- But it doesn't help for means.
- The problems with standard deviations and correlations are
  - Std devs vary over time (turbulent and calm markets).
  - Correlations also increase in turbulent markets.
  - There are too many correlations: $n(n-1)/2$.

## Sampling frequency

:::: {.columns}

::: {.column width="50%"}

::: {.fragment}
If we sample monthly, weekly, $\ldots$ then we have more data points, so estimates are more accurate.
:::

::: {.fragment}
<p align=center> <img src="images/pay-3456736_1920.jpg" height=250 width=400></p>
:::

:::
::: {.column width="50%"}

::: {.fragment}
When we scale to annual parameters, the accuracy gain vanishes for the mean.
:::

<br>

::: {.fragment}
<p align=center> <img src="images/pay-3456722_1920.jpg" height=250 width=400></p>
:::
:::
::::


## Simulation 

. . .

To illustrate effect of sampling frequency,

- Simulate 5,000 25-year histories of monthly returns. 
- Compound monthly returns to get annual returns.
- Compute sampling distributions (across 5,000 samples) of monthly and annual statistics.

#
. . .

``` {.p code-line-numbers=1-5|7-8|9-10|12|13-14}
import numpy as np
from scipy.stats import norm

# monthly parameters
mu, sigma = 0.01, 0.3/np.sqrt(12)  

mrets = norm.rvs(loc=mu, scale=sigma, size=12*25*5000)
mrets = mrets.reshape(12, 25, 5000)
mmeans = np.mean(mrets, axis=(0,1))
msds = np.std(mrets, axis=(0,1))

arets = np.prod(1+mrets, axis=0) - 1
ameans = np.mean(arets, axis=0)
asds = np.std(arets, axis=0)
```

## Means -- sampling monthly doesn't help

. . .


```{python}
import numpy as np
from scipy.stats import norm
from scipy.stats import gaussian_kde as kde
import plotly.graph_objects as go

# monthly parameters
mu, sigma = 0.01, 0.3/np.sqrt(12)  

mrets = norm.rvs(loc=mu, scale=sigma, size=12*25*5000)
mrets = mrets.reshape(12, 25, 5000)
mmeans = 12*np.mean(mrets, axis=(0,1))
msds = np.sqrt(12)*np.std(mrets, axis=(0,1))

arets = np.prod(1+mrets, axis=0) - 1
ameans = np.mean(arets, axis=0)
asds = np.std(arets, axis=0)

adensity = kde(ameans)
mdensity = kde(mmeans)

grid = np.linspace(np.min(ameans), np.max(ameans), 100)
trace1 = go.Scatter(
  x=grid,
  y=adensity(grid),
  mode="lines",
  name="annual"
)

grid = np.linspace(np.min(mmeans), np.max(mmeans), 100)
trace2 = go.Scatter(
  x=grid,
  y=mdensity(grid),
  mode="lines",
  name="12*monthly"
)

fig = go.Figure(trace1)
fig.add_trace(trace2)
fig.update_layout(
    template="plotly_dark",
    xaxis_title="Sample Mean",
    yaxis_title="Density",
    xaxis_tickformat=".0%",
    yaxis_tickformat=".0f",
    xaxis_title_font_size=24,
    yaxis_title_font_size=24,
    font_size=20,
    width=1000,
    height=520,
     legend=dict(
        yanchor="top", 
        y=0.99, 
        xanchor="right", 
        x=0.99
    ),
)
fig.show()

```

## Standard deviations - monthly is better

. . .

```{python}
adensity = kde(asds)
mdensity = kde(msds)

grid = np.linspace(np.min(asds), np.max(asds), 100)
trace1 = go.Scatter(
  x=grid,
  y=adensity(grid),
  mode="lines",
  name="annual"
)

grid = np.linspace(np.min(msds), np.max(msds), 100)
trace2 = go.Scatter(
  x=grid,
  y=mdensity(grid),
  mode="lines",
  name="sqrt(12)*monthly"
)
fig = go.Figure(trace1)
fig.add_trace(trace2)
fig.update_layout(
    template="plotly_dark",
    xaxis_title="Sample Standard Deviation",
    yaxis_title="Density",
    xaxis_tickformat=".0%",
    yaxis_tickformat=".0f",
    xaxis_title_font_size=24,
    yaxis_title_font_size=24,
    font_size=20,
    width=1000,
    height=520,
     legend=dict(
        yanchor="top", 
        y=0.99, 
        xanchor="right", 
        x=0.99
    ),
)
fig.show()

```

. . .

Higher frequency is also better for correlations, covariances, and betas.